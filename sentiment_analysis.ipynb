{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 >Sentiment Analysis</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tweepy\n",
      "  Downloading tweepy-4.10.1-py3-none-any.whl (94 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94 kB 2.3 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting requests<3,>=2.27.0\n",
      "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62 kB 4.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests-oauthlib<2,>=1.2.0 in /opt/miniconda3/lib/python3.8/site-packages (from tweepy) (1.3.0)\n",
      "Collecting oauthlib<4,>=3.2.0\n",
      "  Downloading oauthlib-3.2.1-py3-none-any.whl (151 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 151 kB 12.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.27.0->tweepy) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.27.0->tweepy) (2022.9.14)\n",
      "Collecting charset-normalizer<3,>=2\n",
      "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.27.0->tweepy) (2.9)\n",
      "\u001b[31mERROR: conda 4.14.0 requires ruamel_yaml_conda>=0.11.14, which is not installed.\u001b[0m\n",
      "Installing collected packages: charset-normalizer, requests, oauthlib, tweepy\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.23.0\n",
      "    Uninstalling requests-2.23.0:\n",
      "      Successfully uninstalled requests-2.23.0\n",
      "  Attempting uninstall: oauthlib\n",
      "    Found existing installation: oauthlib 3.1.0\n",
      "    Uninstalling oauthlib-3.1.0:\n",
      "      Successfully uninstalled oauthlib-3.1.0\n",
      "Successfully installed charset-normalizer-2.1.1 oauthlib-3.2.1 requests-2.28.1 tweepy-4.10.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "from datetime import date, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Data Extraction from Twitter API\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = '1D9l2cpV4EJaO1jBrdWU9zfoU' \n",
    "api_key_secret = 'qxyDTwZUABqd0sjaLe1Q3wQSxBhTjRexWbxDptu34fWt51ohpI'\n",
    "access_token = '1572868505137188864-JSJF2tFizDiSvvMTUH5UhGjd1wOn5j'\n",
    "access_token_secret = '6A562B7011LSkzmQs4TNZMLPO3USIw7mh5p89LlyKhOfD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(api_key, api_key_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tweepy.api.API at 0x7fd4287c6be0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#api.search_tweets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dicts = []\n",
    "search_term = 'covid19 covid vaccine'\n",
    "num_tweets = 11000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dates = []\n",
    "today = date.today()\n",
    "for i in range(-477,-470):\n",
    "    target_date = (today + timedelta(days=i)).strftime(\"%Y-%m-%d\")\n",
    "    list_of_dates.append(target_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2021-06-03',\n",
       " '2021-06-04',\n",
       " '2021-06-05',\n",
       " '2021-06-06',\n",
       " '2021-06-07',\n",
       " '2021-06-08',\n",
       " '2021-06-09']"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def get_tweets(search_term = search_term, num_tweets = num_tweets):\n",
    "\n",
    "#     with open(\"sample.json\", \"w\") as outfile:\n",
    "#         for end_date in list_of_dates:\n",
    "#             start_date = (datetime.datetime.strptime(end_date, '%Y-%m-%d') - timedelta(days=1)).strftime(\"%Y-%m-%d\") # Create 1-day windows for extraction\n",
    "#             tweet_count = len(list_of_dicts)\n",
    "\n",
    "# #             tweetCursor = tweepy.Cursor(api.search_tweets,\n",
    "# #                                        q=f'{search_term} since:{start_date} until:{end_date}',\n",
    "# #                                         #q=search_term,\n",
    "# #                                        lang = 'en',\n",
    "# #                                        count = num_tweets,\n",
    "# #                                        tweet_mode = 'extended').items(num_tweets)\n",
    "\n",
    "#             for tweet in tweepy.Cursor(api.search_tweets,\n",
    "#                                        q=f'{search_term} since:{start_date} until:{end_date}',\n",
    "#                                       # q=search_term,\n",
    "#                                        lang = 'en',\n",
    "#                                        count = num_tweets,\n",
    "#                                        tweet_mode = 'extended').items(num_tweets):\n",
    "#                 #if (not tweet.retweeted) and ('RT @' not in tweet.full_text):\n",
    "#                 #if 'RT @' not in tweet.full_text:\n",
    "#                     if tweet.lang == \"en\":\n",
    "#                         tweet_dict = {}\n",
    "#                         tweet_dict['username'] = tweet.user.name\n",
    "#                         tweet_dict['location'] = tweet.user.location\n",
    "#                         tweet_dict['text'] = tweet.full_text \n",
    "#                         tweet_dict['hashtags'] = tweet.entities['hashtags']\n",
    "#                         dtx = tweet.created_at\n",
    "#                         tweet_dict['tweet_date'] = dtx.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "#                         tweet_dict[\"retweeted\"] = tweet.retweeted\n",
    "#                         tweet_dict[\"retweet_count\"] =  tweet.retweet_count\n",
    "#                         tweet_dict[\"favorite_count\"] = tweet.favorite_count\n",
    "#                         #list_of_dicts.append(tweet_dict)\n",
    "#                         json.dump(tweet_dict, outfile)\n",
    "#                         if tweet_count % 10 == 0:\n",
    "#                             print(f'Extracted tweet count = {tweet_count}')\n",
    "#                         tweet_count +=1\n",
    "#                         print(tweet_count)\n",
    "                        \n",
    "#             #print(f'Completed extraction for {start_date} to {end_date}. Sleep for 15 mins')\n",
    "#             #time.sleep(900)\n",
    "#             #print('Ready to go again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(search_term = search_term, num_tweets = num_tweets):\n",
    "#     try:\n",
    "        for end_date in list_of_dates:\n",
    "            start_date = (datetime.datetime.strptime(end_date, '%Y-%m-%d') - timedelta(days=1)).strftime(\"%Y-%m-%d\") # Create 1-day windows for extraction\n",
    "            tweet_count = len(list_of_dicts)\n",
    "\n",
    "            for tweet in tweepy.Cursor(api.search_tweets,\n",
    "                                       q=f'{search_term} since:{start_date} until:{end_date}',\n",
    "                                      # q=search_term,\n",
    "                                       lang = 'en',\n",
    "                                       count = num_tweets,\n",
    "                                       tweet_mode = 'extended').items(num_tweets):\n",
    "                #if (not tweet.retweeted) and ('RT @' not in tweet.full_text):\n",
    "                if 'RT @' not in tweet.full_text:\n",
    "                    if tweet.lang == \"en\":\n",
    "                        tweet_dict = {}\n",
    "                        tweet_dict['username'] = tweet.user.name\n",
    "                        tweet_dict['location'] = tweet.user.location\n",
    "                        tweet_dict['text'] = tweet.full_text \n",
    "                        tweet_dict['hashtags'] = tweet.entities['hashtags']\n",
    "                        dtx = tweet.created_at\n",
    "                        tweet_dict['tweet_date'] = dtx.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "                        tweet_dict[\"retweeted\"] = tweet.retweeted\n",
    "                        tweet_dict[\"retweet_count\"] =  tweet.retweet_count\n",
    "                        tweet_dict[\"favorite_count\"] = tweet.favorite_count\n",
    "                        list_of_dicts.append(tweet_dict)\n",
    "                        #json.dump(tweet_dict, outfile)\n",
    "                        if tweet_count % 500 == 0:\n",
    "                            print(f'Extracted tweet count = {tweet_count}')\n",
    "                        tweet_count +=1\n",
    "                        #print(tweet_count)\n",
    "                        \n",
    "            print(f'Completed extraction for {start_date} to {end_date}. Sleep for 15 mins')\n",
    "            #time.sleep(900)\n",
    "            print('Ready again')\n",
    "#     except tweepy.TweepError:\n",
    "#             print(tweepy.TweepError)\n",
    "#             time.sleep(15 * 60)\n",
    "#         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed extraction for 2021-06-02 to 2021-06-03. Sleep for 15 mins\n",
      "Ready again\n",
      "Completed extraction for 2021-06-03 to 2021-06-04. Sleep for 15 mins\n",
      "Ready again\n",
      "Completed extraction for 2021-06-04 to 2021-06-05. Sleep for 15 mins\n",
      "Ready again\n",
      "Completed extraction for 2021-06-05 to 2021-06-06. Sleep for 15 mins\n",
      "Ready again\n",
      "Completed extraction for 2021-06-06 to 2021-06-07. Sleep for 15 mins\n",
      "Ready again\n",
      "Completed extraction for 2021-06-07 to 2021-06-08. Sleep for 15 mins\n",
      "Ready again\n",
      "Completed extraction for 2021-06-08 to 2021-06-09. Sleep for 15 mins\n",
      "Ready again\n"
     ]
    }
   ],
   "source": [
    "get_tweets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1377"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jerry Rider</td>\n",
       "      <td>QLD Australia</td>\n",
       "      <td>More evidence of Covid-19 vaccine shedding, lo...</td>\n",
       "      <td>[{'text': 'COVID19', 'indices': [115, 123]}, {...</td>\n",
       "      <td>09/14/2022, 23:32:18</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Northern Qld PHN</td>\n",
       "      <td>Cairns, Queensland</td>\n",
       "      <td>ðŸ’ªðŸ’‰MACKAY COVID-19 VAX CLINICðŸ’‰ðŸ’ª | A free COVID-...</td>\n",
       "      <td>[{'text': 'Mackay', 'indices': [179, 186]}, {'...</td>\n",
       "      <td>09/14/2022, 23:30:05</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jonathan Bradley</td>\n",
       "      <td>Canada</td>\n",
       "      <td>â€œThe reported incident counts reflect #prelimi...</td>\n",
       "      <td>[{'text': 'preliminaryinformation', 'indices':...</td>\n",
       "      <td>09/14/2022, 23:29:42</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Northern Qld PHN</td>\n",
       "      <td>Cairns, Queensland</td>\n",
       "      <td>ðŸ’ªðŸ’‰TOWNSVILLE COVID-19 VAX CLINIC ðŸ’‰ðŸ’ª | A free C...</td>\n",
       "      <td>[{'text': 'Townsville', 'indices': [188, 199]}...</td>\n",
       "      <td>09/14/2022, 23:24:16</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Patrick</td>\n",
       "      <td></td>\n",
       "      <td>@TomiLahren Same, never been vaxxed for \"covid...</td>\n",
       "      <td>[{'text': 'CovidBS', 'indices': [185, 193]}, {...</td>\n",
       "      <td>09/14/2022, 23:22:12</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           username            location  \\\n",
       "0       Jerry Rider       QLD Australia   \n",
       "1  Northern Qld PHN  Cairns, Queensland   \n",
       "2  Jonathan Bradley              Canada   \n",
       "3  Northern Qld PHN  Cairns, Queensland   \n",
       "4           Patrick                       \n",
       "\n",
       "                                                text  \\\n",
       "0  More evidence of Covid-19 vaccine shedding, lo...   \n",
       "1  ðŸ’ªðŸ’‰MACKAY COVID-19 VAX CLINICðŸ’‰ðŸ’ª | A free COVID-...   \n",
       "2  â€œThe reported incident counts reflect #prelimi...   \n",
       "3  ðŸ’ªðŸ’‰TOWNSVILLE COVID-19 VAX CLINIC ðŸ’‰ðŸ’ª | A free C...   \n",
       "4  @TomiLahren Same, never been vaxxed for \"covid...   \n",
       "\n",
       "                                            hashtags            tweet_date  \\\n",
       "0  [{'text': 'COVID19', 'indices': [115, 123]}, {...  09/14/2022, 23:32:18   \n",
       "1  [{'text': 'Mackay', 'indices': [179, 186]}, {'...  09/14/2022, 23:30:05   \n",
       "2  [{'text': 'preliminaryinformation', 'indices':...  09/14/2022, 23:29:42   \n",
       "3  [{'text': 'Townsville', 'indices': [188, 199]}...  09/14/2022, 23:24:16   \n",
       "4  [{'text': 'CovidBS', 'indices': [185, 193]}, {...  09/14/2022, 23:22:12   \n",
       "\n",
       "   retweeted  retweet_count  favorite_count  \n",
       "0      False              1               1  \n",
       "1      False              1               2  \n",
       "2      False              0               0  \n",
       "3      False              1               2  \n",
       "4      False              0               2  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(list_of_dicts)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'09/14/2022': 205,\n",
       " '09/15/2022': 177,\n",
       " '09/16/2022': 181,\n",
       " '09/17/2022': 134,\n",
       " '09/18/2022': 152,\n",
       " '09/19/2022': 166,\n",
       " '09/20/2022': 176,\n",
       " '09/21/2022': 186}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_set = {}\n",
    "\n",
    "for idx in range(0, len(df)):\n",
    "    s = df[\"tweet_date\"][idx].split(\",\")[0]\n",
    "    #print(type(s))\n",
    "    if s in s_set.keys():\n",
    "        s_set[s] += 1\n",
    "    else:\n",
    "        s_set[s] = 1\n",
    "    \n",
    "s_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1377"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"testdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
