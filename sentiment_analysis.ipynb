{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 >Sentiment Analysis</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tweepy\n",
      "  Downloading tweepy-4.10.1-py3-none-any.whl (94 kB)\n",
      "\u001b[K     |████████████████████████████████| 94 kB 2.3 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting requests<3,>=2.27.0\n",
      "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "\u001b[K     |████████████████████████████████| 62 kB 4.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests-oauthlib<2,>=1.2.0 in /opt/miniconda3/lib/python3.8/site-packages (from tweepy) (1.3.0)\n",
      "Collecting oauthlib<4,>=3.2.0\n",
      "  Downloading oauthlib-3.2.1-py3-none-any.whl (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 12.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.27.0->tweepy) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.27.0->tweepy) (2022.9.14)\n",
      "Collecting charset-normalizer<3,>=2\n",
      "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.27.0->tweepy) (2.9)\n",
      "\u001b[31mERROR: conda 4.14.0 requires ruamel_yaml_conda>=0.11.14, which is not installed.\u001b[0m\n",
      "Installing collected packages: charset-normalizer, requests, oauthlib, tweepy\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.23.0\n",
      "    Uninstalling requests-2.23.0:\n",
      "      Successfully uninstalled requests-2.23.0\n",
      "  Attempting uninstall: oauthlib\n",
      "    Found existing installation: oauthlib 3.1.0\n",
      "    Uninstalling oauthlib-3.1.0:\n",
      "      Successfully uninstalled oauthlib-3.1.0\n",
      "Successfully installed charset-normalizer-2.1.1 oauthlib-3.2.1 requests-2.28.1 tweepy-4.10.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting demoji\n",
      "  Downloading demoji-1.1.0-py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 1.8 MB/s eta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: demoji\n",
      "Successfully installed demoji-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install demoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sheenasalwan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "from datetime import date, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import demoji\n",
    "from emoji.unicode_codes import UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-b6fe2259445e>:1: FutureWarning: The demoji.download_codes attribute is deprecated and will be removed from demoji in a future version. It is an unused attribute as emoji codes are now distributed directly with the demoji package.\n",
      "  demoji.download_codes()\n"
     ]
    }
   ],
   "source": [
    "demoji.download_codes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Data Extraction from Twitter API\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = '1D9l2cpV4EJaO1jBrdWU9zfoU' \n",
    "api_key_secret = 'qxyDTwZUABqd0sjaLe1Q3wQSxBhTjRexWbxDptu34fWt51ohpI'\n",
    "access_token = '1572868505137188864-JSJF2tFizDiSvvMTUH5UhGjd1wOn5j'\n",
    "access_token_secret = '6A562B7011LSkzmQs4TNZMLPO3USIw7mh5p89LlyKhOfD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(api_key, api_key_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tweepy.api.API at 0x7fd4287c6be0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#api.search_tweets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dicts = []\n",
    "search_term = 'covid19 covid vaccine'\n",
    "num_tweets = 11000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dates = []\n",
    "today = date.today()\n",
    "for i in range(-477,-470):\n",
    "    target_date = (today + timedelta(days=i)).strftime(\"%Y-%m-%d\")\n",
    "    list_of_dates.append(target_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(search_term = search_term, num_tweets = num_tweets):\n",
    "#     try:\n",
    "        for end_date in list_of_dates:\n",
    "            start_date = (datetime.datetime.strptime(end_date, '%Y-%m-%d') - timedelta(days=1)).strftime(\"%Y-%m-%d\") # Create 1-day windows for extraction\n",
    "            tweet_count = len(list_of_dicts)\n",
    "\n",
    "            for tweet in tweepy.Cursor(api.search_tweets,\n",
    "                                       q=f'{search_term} since:{start_date} until:{end_date}',\n",
    "                                      # q=search_term,\n",
    "                                       lang = 'en',\n",
    "                                       count = num_tweets,\n",
    "                                       tweet_mode = 'extended').items(num_tweets):\n",
    "                #if (not tweet.retweeted) and ('RT @' not in tweet.full_text):\n",
    "                if 'RT @' not in tweet.full_text:\n",
    "                    if tweet.lang == \"en\":\n",
    "                        tweet_dict = {}\n",
    "                        tweet_dict['username'] = tweet.user.name\n",
    "                        tweet_dict['location'] = tweet.user.location\n",
    "                        tweet_dict['text'] = tweet.full_text \n",
    "                        tweet_dict['hashtags'] = tweet.entities['hashtags']\n",
    "                        dtx = tweet.created_at\n",
    "                        tweet_dict['tweet_date'] = dtx.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "                        tweet_dict[\"retweeted\"] = tweet.retweeted\n",
    "                        tweet_dict[\"retweet_count\"] =  tweet.retweet_count\n",
    "                        tweet_dict[\"favorite_count\"] = tweet.favorite_count\n",
    "                        list_of_dicts.append(tweet_dict)\n",
    "                        #json.dump(tweet_dict, outfile)\n",
    "                        if tweet_count % 500 == 0:\n",
    "                            print(f'Extracted tweet count = {tweet_count}')\n",
    "                        tweet_count +=1\n",
    "                        #print(tweet_count)\n",
    "                        \n",
    "            print(f'Completed extraction for {start_date} to {end_date}. Sleep for 15 mins')\n",
    "            #time.sleep(900)\n",
    "            print('Ready again')\n",
    "#     except tweepy.TweepError:\n",
    "#             print(tweepy.TweepError)\n",
    "#             time.sleep(15 * 60)\n",
    "#         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed extraction for 2021-06-02 to 2021-06-03. Sleep for 15 mins\n",
      "Ready again\n",
      "Completed extraction for 2021-06-03 to 2021-06-04. Sleep for 15 mins\n",
      "Ready again\n",
      "Completed extraction for 2021-06-04 to 2021-06-05. Sleep for 15 mins\n",
      "Ready again\n",
      "Completed extraction for 2021-06-05 to 2021-06-06. Sleep for 15 mins\n",
      "Ready again\n",
      "Completed extraction for 2021-06-06 to 2021-06-07. Sleep for 15 mins\n",
      "Ready again\n",
      "Completed extraction for 2021-06-07 to 2021-06-08. Sleep for 15 mins\n",
      "Ready again\n",
      "Completed extraction for 2021-06-08 to 2021-06-09. Sleep for 15 mins\n",
      "Ready again\n"
     ]
    }
   ],
   "source": [
    "get_tweets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO BE UNCOMMENTED FOR DATA EXTRACTION TESTING\n",
    "# df = pd.DataFrame(list_of_dicts)\n",
    "# df.head()\n",
    "# ============\n",
    "# s_set = {}\n",
    "\n",
    "# for idx in range(0, len(df)):\n",
    "#     s = df[\"tweet_date\"][idx].split(\",\")[0]\n",
    "#     #print(type(s))\n",
    "#     if s in s_set.keys():\n",
    "#         s_set[s] += 1\n",
    "#     else:\n",
    "#         s_set[s] = 1\n",
    "    \n",
    "# s_set\n",
    "#=============\n",
    "# df.to_csv(\"vaccination_all_tweets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Data Exploring\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_created</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_favourites</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>source</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>is_retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>206964</th>\n",
       "      <td>1445954643419226114</td>\n",
       "      <td>VaxBLR</td>\n",
       "      <td>Bengaluru, India</td>\n",
       "      <td>Hourly updates on FREE and PAID 18+ and 45+ va...</td>\n",
       "      <td>2021-06-21 08:44:34</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-10-07 03:30:26</td>\n",
       "      <td>18-44 #BBMP #Bengaluru #CovidVaccine Availabil...</td>\n",
       "      <td>['BBMP', 'Bengaluru', 'CovidVaccine', 'COVISHI...</td>\n",
       "      <td>VaxBlr</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206965</th>\n",
       "      <td>1445954599345475592</td>\n",
       "      <td>VaxBLR</td>\n",
       "      <td>Bengaluru, India</td>\n",
       "      <td>Hourly updates on FREE and PAID 18+ and 45+ va...</td>\n",
       "      <td>2021-06-21 08:44:34</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-10-07 03:30:15</td>\n",
       "      <td>18-44 #URBAN #Bengaluru #CovidVaccine Availabi...</td>\n",
       "      <td>['URBAN', 'Bengaluru', 'CovidVaccine', 'COVISH...</td>\n",
       "      <td>VaxBlr</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206966</th>\n",
       "      <td>1445947047052333057</td>\n",
       "      <td>VaxBLR</td>\n",
       "      <td>Bengaluru, India</td>\n",
       "      <td>Hourly updates on FREE and PAID 18+ and 45+ va...</td>\n",
       "      <td>2021-06-21 08:44:34</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-10-07 03:00:15</td>\n",
       "      <td>45+ #URBAN #Bengaluru #CovidVaccine Availabili...</td>\n",
       "      <td>['URBAN', 'Bengaluru', 'CovidVaccine', 'COVISH...</td>\n",
       "      <td>VaxBlr</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id user_name     user_location  \\\n",
       "206964  1445954643419226114    VaxBLR  Bengaluru, India   \n",
       "206965  1445954599345475592    VaxBLR  Bengaluru, India   \n",
       "206966  1445947047052333057    VaxBLR  Bengaluru, India   \n",
       "\n",
       "                                         user_description  \\\n",
       "206964  Hourly updates on FREE and PAID 18+ and 45+ va...   \n",
       "206965  Hourly updates on FREE and PAID 18+ and 45+ va...   \n",
       "206966  Hourly updates on FREE and PAID 18+ and 45+ va...   \n",
       "\n",
       "               user_created  user_followers  user_friends  user_favourites  \\\n",
       "206964  2021-06-21 08:44:34              26             0                0   \n",
       "206965  2021-06-21 08:44:34              26             0                0   \n",
       "206966  2021-06-21 08:44:34              26             0                0   \n",
       "\n",
       "        user_verified                 date  \\\n",
       "206964          False  2021-10-07 03:30:26   \n",
       "206965          False  2021-10-07 03:30:15   \n",
       "206966          False  2021-10-07 03:00:15   \n",
       "\n",
       "                                                     text  \\\n",
       "206964  18-44 #BBMP #Bengaluru #CovidVaccine Availabil...   \n",
       "206965  18-44 #URBAN #Bengaluru #CovidVaccine Availabi...   \n",
       "206966  45+ #URBAN #Bengaluru #CovidVaccine Availabili...   \n",
       "\n",
       "                                                 hashtags  source  retweets  \\\n",
       "206964  ['BBMP', 'Bengaluru', 'CovidVaccine', 'COVISHI...  VaxBlr         0   \n",
       "206965  ['URBAN', 'Bengaluru', 'CovidVaccine', 'COVISH...  VaxBlr         0   \n",
       "206966  ['URBAN', 'Bengaluru', 'CovidVaccine', 'COVISH...  VaxBlr         0   \n",
       "\n",
       "        favorites  is_retweet  \n",
       "206964          1       False  \n",
       "206965          0       False  \n",
       "206966          0       False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet = pd.read_csv(\"data/vaccination_all_tweets.csv\")\n",
    "df_tweet.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(206967, 16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_favourites</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.069670e+05</td>\n",
       "      <td>2.069670e+05</td>\n",
       "      <td>206967.000000</td>\n",
       "      <td>2.069670e+05</td>\n",
       "      <td>206967.000000</td>\n",
       "      <td>206967.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.402529e+18</td>\n",
       "      <td>9.356921e+04</td>\n",
       "      <td>983.137118</td>\n",
       "      <td>1.187433e+04</td>\n",
       "      <td>2.389091</td>\n",
       "      <td>10.334483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.571008e+16</td>\n",
       "      <td>8.188852e+05</td>\n",
       "      <td>5390.710356</td>\n",
       "      <td>3.869035e+04</td>\n",
       "      <td>44.710131</td>\n",
       "      <td>160.316483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.337728e+18</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.380516e+18</td>\n",
       "      <td>5.900000e+01</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>5.700000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.405382e+18</td>\n",
       "      <td>3.390000e+02</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>9.520000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.422578e+18</td>\n",
       "      <td>1.521000e+03</td>\n",
       "      <td>786.000000</td>\n",
       "      <td>7.130000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.449092e+18</td>\n",
       "      <td>1.620117e+07</td>\n",
       "      <td>582461.000000</td>\n",
       "      <td>1.221784e+06</td>\n",
       "      <td>11288.000000</td>\n",
       "      <td>25724.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  user_followers   user_friends  user_favourites  \\\n",
       "count  2.069670e+05    2.069670e+05  206967.000000     2.069670e+05   \n",
       "mean   1.402529e+18    9.356921e+04     983.137118     1.187433e+04   \n",
       "std    2.571008e+16    8.188852e+05    5390.710356     3.869035e+04   \n",
       "min    1.337728e+18    0.000000e+00       0.000000     0.000000e+00   \n",
       "25%    1.380516e+18    5.900000e+01      25.000000     5.700000e+01   \n",
       "50%    1.405382e+18    3.390000e+02     227.000000     9.520000e+02   \n",
       "75%    1.422578e+18    1.521000e+03     786.000000     7.130000e+03   \n",
       "max    1.449092e+18    1.620117e+07  582461.000000     1.221784e+06   \n",
       "\n",
       "            retweets      favorites  \n",
       "count  206967.000000  206967.000000  \n",
       "mean        2.389091      10.334483  \n",
       "std        44.710131     160.316483  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         0.000000       0.000000  \n",
       "75%         0.000000       2.000000  \n",
       "max     11288.000000   25724.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Text Cleaning and Processing\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         folks said daikon paste could treat cytokine s...\n",
       "1         world wrong side history year hopefully bigges...\n",
       "2         coronavirus sputnikv astrazeneca pfizerbiontec...\n",
       "3         facts immutable senator even youre ethically s...\n",
       "4         explain need vaccine borisjohnson matthancock ...\n",
       "                                ...                        \n",
       "206962    45 urban bengaluru covidvaccine availability 3...\n",
       "206963    pincode 560011 sputnik v dose 1 100 slots age ...\n",
       "206964    1844 bbmp bengaluru covidvaccine availability ...\n",
       "206965    1844 urban bengaluru covidvaccine availability...\n",
       "206966    45 urban bengaluru covidvaccine availability 0...\n",
       "Name: text, Length: 206967, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lowercase and url removal\n",
    "\n",
    "def process_tweet(text):\n",
    "    text = text.lower()             # convert to lowercase\n",
    "    text = re.sub(r\"http\\S+\", \"\", text) # url removal\n",
    "    return text\n",
    "\n",
    "df_tweet[\"text\"] = df_tweet[\"text\"].apply(lambda text: process_tweet(text))\n",
    "df_tweet[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         same folks said daikon paste could treat a cyt...\n",
       "1         while the world has been on the wrong side of ...\n",
       "2         coronavirus sputnikv astrazeneca pfizerbiontec...\n",
       "3         facts are immutable senator even when youre no...\n",
       "4         explain to me again why we need a vaccine bori...\n",
       "                                ...                        \n",
       "206962    45 urban bengaluru covidvaccine availability f...\n",
       "206963    pincode 560011\\nsputnik v  dose 1 100 slots\\n\\...\n",
       "206964    1844 bbmp bengaluru covidvaccine availability ...\n",
       "206965    1844 urban bengaluru covidvaccine availability...\n",
       "206966    45 urban bengaluru covidvaccine availability f...\n",
       "Name: text, Length: 206967, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Punctuation Removal\n",
    "\n",
    "punctuation_removal = string.punctuation\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"custom function to remove the punctuation\"\"\"\n",
    "    return text.translate(str.maketrans('', '', punctuation_removal))\n",
    "\n",
    "df_tweet[\"text\"] = df_tweet[\"text\"].apply(lambda text: remove_punctuation(text))\n",
    "df_tweet[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         folks said daikon paste could treat cytokine s...\n",
       "1         world wrong side history year hopefully bigges...\n",
       "2         coronavirus sputnikv astrazeneca pfizerbiontec...\n",
       "3         facts immutable senator even youre ethically s...\n",
       "4         explain need vaccine borisjohnson matthancock ...\n",
       "                                ...                        \n",
       "206962    45 urban bengaluru covidvaccine availability 3...\n",
       "206963    pincode 560011 sputnik v dose 1 100 slots age ...\n",
       "206964    1844 bbmp bengaluru covidvaccine availability ...\n",
       "206965    1844 urban bengaluru covidvaccine availability...\n",
       "206966    45 urban bengaluru covidvaccine availability 0...\n",
       "Name: text, Length: 206967, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stopword Removal\n",
    "\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"custom function to remove the stopwords\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "df_tweet[\"text\"] = df_tweet[\"text\"].apply(lambda text: remove_stopwords(text))\n",
    "df_tweet[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         folks said daikon paste could treat cytokine s...\n",
       "1         world wrong side history year hopefully bigges...\n",
       "2         coronavirus sputnikv astrazeneca pfizerbiontec...\n",
       "3         facts immutable senator even youre ethically s...\n",
       "4         explain need vaccine borisjohnson matthancock ...\n",
       "                                ...                        \n",
       "206962    45 urban bengaluru covidvaccine availability 3...\n",
       "206963    pincode 560011 sputnik v dose 1 100 slots age ...\n",
       "206964    1844 bbmp bengaluru covidvaccine availability ...\n",
       "206965    1844 urban bengaluru covidvaccine availability...\n",
       "206966    45 urban bengaluru covidvaccine availability 0...\n",
       "Name: text, Length: 206967, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# emoji convert to text\n",
    "\n",
    "def convert_emoji_to_text(tweet):\n",
    "    tokens = tweet.split()\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token in UNICODE_EMOJI[\"en\"]: \n",
    "            emo_desc = demoji.findall(token)[token]\n",
    "            new_rep = \"_\".join(emo_desc.split(\":\")[0].split())\n",
    "            tokens[i] = new_rep\n",
    "            \n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df_tweet[\"text\"] = df_tweet[\"text\"].apply(lambda text: convert_emoji_to_text(text))\n",
    "df_tweet[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Feature Engineering\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average length of sentence\n",
    "def avg_len_sent(text):\n",
    "    '''Calculates the average length of sentences, in tokens'''\n",
    "    token_count = len(text.split())\n",
    "    sent_count = text.count(\". \") + 1\n",
    "    if sent_count != 0:\n",
    "        return token_count / sent_count\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet[\"avg_len_sent\"] = df_tweet[\"text\"].apply(lambda text:avg_len_sent(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
